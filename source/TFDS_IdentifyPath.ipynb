{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "svpI0FxXl7Ih"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/samaagazzaz/miniforge3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "ds, ds_info = tfds.load(\n",
        "  'cifar10',\n",
        "  split=['train', 'test'],\n",
        "  as_supervised=True,\n",
        "  shuffle_files=True,\n",
        "  with_info=True\n",
        ")\n",
        "\n",
        "ds_train = ds[0]\n",
        "ds_test = ds[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "83JUZ6ffsq4J"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "def pipeline(ds):\n",
        "  ds = ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "ds_train = pipeline(ds_train)\n",
        "ds_test = pipeline(ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XJOqnreYmun1"
      },
      "outputs": [],
      "source": [
        "ds_train_np = tfds.as_numpy(ds_train)\n",
        "ds_test_np = tfds.as_numpy(ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tGgbKARerHjg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "ds_train_img = list()\n",
        "ds_train_label = list()\n",
        "for ex in ds_train_np:\n",
        "  ds_train_img.append(ex[0])\n",
        "  ds_train_label.append(ex[1])\n",
        "\n",
        "\n",
        "ds_test_img = list()\n",
        "ds_test_label = list()\n",
        "for ex in ds_test_np:\n",
        "  ds_test_img.append(ex[0])\n",
        "  ds_test_label.append(ex[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0cvljYcDtRDC"
      },
      "outputs": [],
      "source": [
        "ds_train_img = np.array(ds_train_img)\n",
        "reshaped_train=ds_train_img.reshape(50000,3072)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "shZU7XT0YqdD"
      },
      "outputs": [],
      "source": [
        "ds_test_img = np.array(ds_test_img)\n",
        "reshaped_test=ds_test_img.reshape(10000,3072)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VhPmh5LixYmX"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans \n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkQus4jUxa20",
        "outputId": "e087d0c9-076a-4519-9c8b-cdbf57939773"
      },
      "outputs": [],
      "source": [
        "n_categories=4\n",
        "pca = PCA(n_components=10)\n",
        "kmeans = KMeans(n_clusters=n_categories,max_iter=200)\n",
        "predictor = Pipeline([('pca', pca), ('kmeans', kmeans)])\n",
        "predict = predictor.fit(reshaped_train).predict(reshaped_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9mX5ia7MW7Dk"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"kmeans_predictor.pkl\", \"wb\") as f:\n",
        "    pickle.dump(predictor, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nNt--HsaZS0j"
      },
      "outputs": [],
      "source": [
        "# The variable ds_train_img has the original data. The variable predict has the cluster/shard info\n",
        "# divide data from \"ds_train_img\" to 4 shards based on \"predict\"\n",
        "shards = [list() for x in range(4)]\n",
        "labels_shards = [list() for x in range(4)]\n",
        "\n",
        "for i in range(len(predict)):\n",
        "  if predict[i] == 0:\n",
        "    # put \"ds_train_img[i]\" in shard_1\n",
        "    shards[0].append(ds_train_img[i])\n",
        "    labels_shards[0].append(ds_train_label[i])\n",
        "  elif predict[i] == 1:\n",
        "    # put \"ds_train_img[i]\" in shard_2\n",
        "    shards[1].append(ds_train_img[i])\n",
        "    labels_shards[1].append(ds_train_label[i])\n",
        "  elif predict[i] == 2:\n",
        "    # put \"ds_train_img[i]\" in shard_3\n",
        "    shards[2].append(ds_train_img[i])\n",
        "    labels_shards[2].append(ds_train_label[i])\n",
        "  else:\n",
        "    # put \"ds_train_img[i]\" in shard_4\n",
        "    shards[3].append(ds_train_img[i])\n",
        "    labels_shards[3].append(ds_train_label[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "C4Z2CJz7mdG6"
      },
      "outputs": [],
      "source": [
        "vgg_benchmark_model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT4-2-8AnCei",
        "outputId": "fbc73c18-065f-4552-e599-5eb51d276f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the root layer count is :  8\n"
          ]
        }
      ],
      "source": [
        "from math import ceil\n",
        "\n",
        "temp_model = tf.keras.models.clone_model(vgg_benchmark_model)\n",
        "layer_count = ceil(len(temp_model.layers)*0.5)\n",
        "print('the root layer count is : ', layer_count)\n",
        "\n",
        "root_model = tf.keras.models.Sequential(temp_model.layers[:layer_count])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0MWSKvOnV_O",
        "outputId": "c2e932b6-e675-4e4d-b0e5-7cef7060d980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building model 0\n",
            "the second half layer count is :  8\n",
            "building model 1\n",
            "the second half layer count is :  8\n",
            "building model 2\n",
            "the second half layer count is :  8\n",
            "building model 3\n",
            "the second half layer count is :  8\n"
          ]
        }
      ],
      "source": [
        "constituent_models = list(range(4))\n",
        "for i in range(4):\n",
        "      print('building model', i)\n",
        "\n",
        "      temp_model = tf.keras.models.clone_model(vgg_benchmark_model)\n",
        "      layer_count = ceil(len(temp_model.layers)*(0.5))\n",
        "      print('the second half layer count is : ', len(temp_model.layers) - layer_count)\n",
        "      # layer_count = len(temp_model.layers) - layer_count\n",
        "      part_model = tf.keras.models.Sequential(temp_model.layers[layer_count:])\n",
        "\n",
        "      constituent_models[i] = tf.keras.models.Sequential([\n",
        "        root_model,\n",
        "        part_model\n",
        "        ])\n",
        "\n",
        "      constituent_models[i].compile(\n",
        "          optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvhDlcZJq8Qs",
        "outputId": "3d855927-f530-41e5-cb75-da2b192c1f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model[ 0 ]\n",
            "Epoch 1/20\n",
            "51/51 [==============================] - 6s 112ms/step - loss: 2.1029 - sparse_categorical_accuracy: 0.2582 - val_loss: 2.1649 - val_sparse_categorical_accuracy: 0.1626\n",
            "Epoch 2/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.7499 - sparse_categorical_accuracy: 0.3904 - val_loss: 1.8233 - val_sparse_categorical_accuracy: 0.3259\n",
            "Epoch 3/20\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.4844 - sparse_categorical_accuracy: 0.4790 - val_loss: 1.6518 - val_sparse_categorical_accuracy: 0.3762\n",
            "Epoch 4/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.3046 - sparse_categorical_accuracy: 0.5421 - val_loss: 1.5491 - val_sparse_categorical_accuracy: 0.4093\n",
            "Epoch 5/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.1647 - sparse_categorical_accuracy: 0.5936 - val_loss: 1.5377 - val_sparse_categorical_accuracy: 0.4285\n",
            "Epoch 6/20\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.0242 - sparse_categorical_accuracy: 0.6432 - val_loss: 1.4749 - val_sparse_categorical_accuracy: 0.4645\n",
            "Epoch 7/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9163 - sparse_categorical_accuracy: 0.6824 - val_loss: 1.4772 - val_sparse_categorical_accuracy: 0.4729\n",
            "Epoch 8/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8215 - sparse_categorical_accuracy: 0.7124 - val_loss: 1.5215 - val_sparse_categorical_accuracy: 0.4636\n",
            "Epoch 9/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7347 - sparse_categorical_accuracy: 0.7417 - val_loss: 1.7795 - val_sparse_categorical_accuracy: 0.4168\n",
            "Epoch 10/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6622 - sparse_categorical_accuracy: 0.7629 - val_loss: 1.7325 - val_sparse_categorical_accuracy: 0.4387\n",
            "Epoch 11/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.8056 - val_loss: 1.6257 - val_sparse_categorical_accuracy: 0.4865\n",
            "Epoch 12/20\n",
            "51/51 [==============================] - 6s 108ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8100 - val_loss: 1.7310 - val_sparse_categorical_accuracy: 0.4776\n",
            "Epoch 13/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.8390 - val_loss: 1.7690 - val_sparse_categorical_accuracy: 0.4617\n",
            "Epoch 14/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.4120 - sparse_categorical_accuracy: 0.8538 - val_loss: 1.9265 - val_sparse_categorical_accuracy: 0.4601\n",
            "Epoch 15/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.3592 - sparse_categorical_accuracy: 0.8714 - val_loss: 2.0611 - val_sparse_categorical_accuracy: 0.4792\n",
            "Epoch 16/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8806 - val_loss: 2.1364 - val_sparse_categorical_accuracy: 0.4839\n",
            "Epoch 17/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.3348 - sparse_categorical_accuracy: 0.8815 - val_loss: 1.9233 - val_sparse_categorical_accuracy: 0.5091\n",
            "Epoch 18/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.2943 - sparse_categorical_accuracy: 0.8955 - val_loss: 2.0464 - val_sparse_categorical_accuracy: 0.5067\n",
            "Epoch 19/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.2126 - sparse_categorical_accuracy: 0.9260 - val_loss: 2.1778 - val_sparse_categorical_accuracy: 0.5161\n",
            "Epoch 20/20\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9490 - val_loss: 2.3124 - val_sparse_categorical_accuracy: 0.5084\n",
            "training model[ 1 ]\n",
            "Epoch 1/20\n",
            "55/55 [==============================] - 6s 111ms/step - loss: 2.1938 - sparse_categorical_accuracy: 0.2476 - val_loss: 1.8421 - val_sparse_categorical_accuracy: 0.3048\n",
            "Epoch 2/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 1.6612 - sparse_categorical_accuracy: 0.3881 - val_loss: 1.5327 - val_sparse_categorical_accuracy: 0.4317\n",
            "Epoch 3/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 1.4233 - sparse_categorical_accuracy: 0.4798 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.4790\n",
            "Epoch 4/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 1.2190 - sparse_categorical_accuracy: 0.5601 - val_loss: 1.3578 - val_sparse_categorical_accuracy: 0.5176\n",
            "Epoch 5/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 1.0423 - sparse_categorical_accuracy: 0.6308 - val_loss: 1.4177 - val_sparse_categorical_accuracy: 0.5201\n",
            "Epoch 6/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.8621 - sparse_categorical_accuracy: 0.7051 - val_loss: 1.5073 - val_sparse_categorical_accuracy: 0.5179\n",
            "Epoch 7/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.7840 - sparse_categorical_accuracy: 0.7221 - val_loss: 1.4607 - val_sparse_categorical_accuracy: 0.5330\n",
            "Epoch 8/20\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.7053 - sparse_categorical_accuracy: 0.7562 - val_loss: 1.5058 - val_sparse_categorical_accuracy: 0.5399\n",
            "Epoch 9/20\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.8038 - val_loss: 1.5136 - val_sparse_categorical_accuracy: 0.5443\n",
            "Epoch 10/20\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.4932 - sparse_categorical_accuracy: 0.8249 - val_loss: 1.6326 - val_sparse_categorical_accuracy: 0.5332\n",
            "Epoch 11/20\n",
            "55/55 [==============================] - 6s 104ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8503 - val_loss: 1.6692 - val_sparse_categorical_accuracy: 0.5535\n",
            "Epoch 12/20\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.3220 - sparse_categorical_accuracy: 0.8899 - val_loss: 1.8500 - val_sparse_categorical_accuracy: 0.5429\n",
            "Epoch 13/20\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.2824 - sparse_categorical_accuracy: 0.9032 - val_loss: 1.8691 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 14/20\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9216 - val_loss: 2.1678 - val_sparse_categorical_accuracy: 0.5480\n",
            "Epoch 15/20\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.1970 - sparse_categorical_accuracy: 0.9340 - val_loss: 2.5615 - val_sparse_categorical_accuracy: 0.5246\n",
            "Epoch 16/20\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.1639 - sparse_categorical_accuracy: 0.9452 - val_loss: 2.3032 - val_sparse_categorical_accuracy: 0.5501\n",
            "Epoch 17/20\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9602 - val_loss: 2.4925 - val_sparse_categorical_accuracy: 0.5473\n",
            "Epoch 18/20\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.1100 - sparse_categorical_accuracy: 0.9663 - val_loss: 2.6640 - val_sparse_categorical_accuracy: 0.5483\n",
            "Epoch 19/20\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9621 - val_loss: 2.5101 - val_sparse_categorical_accuracy: 0.5678\n",
            "Epoch 20/20\n",
            "55/55 [==============================] - 6s 104ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9795 - val_loss: 2.6322 - val_sparse_categorical_accuracy: 0.5736\n",
            "training model[ 2 ]\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 2.9408 - sparse_categorical_accuracy: 0.2338 - val_loss: 2.1570 - val_sparse_categorical_accuracy: 0.1746\n",
            "Epoch 2/20\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 1.7451 - sparse_categorical_accuracy: 0.3506 - val_loss: 1.7663 - val_sparse_categorical_accuracy: 0.3521\n",
            "Epoch 3/20\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 1.4539 - sparse_categorical_accuracy: 0.4596 - val_loss: 1.5819 - val_sparse_categorical_accuracy: 0.4080\n",
            "Epoch 4/20\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 1.2360 - sparse_categorical_accuracy: 0.5520 - val_loss: 1.4755 - val_sparse_categorical_accuracy: 0.4519\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 1.0226 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.4018 - val_sparse_categorical_accuracy: 0.4878\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.8114 - sparse_categorical_accuracy: 0.7191 - val_loss: 1.3941 - val_sparse_categorical_accuracy: 0.5083\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 4s 122ms/step - loss: 0.6317 - sparse_categorical_accuracy: 0.7884 - val_loss: 1.4366 - val_sparse_categorical_accuracy: 0.5125\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.8167 - val_loss: 1.3485 - val_sparse_categorical_accuracy: 0.5349\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.5313 - sparse_categorical_accuracy: 0.8113 - val_loss: 1.6514 - val_sparse_categorical_accuracy: 0.4777\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8474 - val_loss: 1.5643 - val_sparse_categorical_accuracy: 0.5078\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.3909 - sparse_categorical_accuracy: 0.8633 - val_loss: 1.7653 - val_sparse_categorical_accuracy: 0.5082\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.9001 - val_loss: 1.8096 - val_sparse_categorical_accuracy: 0.5059\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.9133 - val_loss: 1.8287 - val_sparse_categorical_accuracy: 0.4959\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 4s 115ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9314 - val_loss: 1.9340 - val_sparse_categorical_accuracy: 0.5117\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 4s 115ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9445 - val_loss: 1.7305 - val_sparse_categorical_accuracy: 0.5230\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 4s 115ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9658 - val_loss: 1.8402 - val_sparse_categorical_accuracy: 0.5336\n",
            "Epoch 17/20\n",
            "33/33 [==============================] - 4s 115ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9807 - val_loss: 2.2138 - val_sparse_categorical_accuracy: 0.5144\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9906 - val_loss: 2.1702 - val_sparse_categorical_accuracy: 0.5341\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 4s 122ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9987 - val_loss: 2.2103 - val_sparse_categorical_accuracy: 0.5439\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.4057 - val_sparse_categorical_accuracy: 0.5444\n",
            "training model[ 3 ]\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 2.5904 - sparse_categorical_accuracy: 0.2017 - val_loss: 1.8109 - val_sparse_categorical_accuracy: 0.3472\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 6s 103ms/step - loss: 1.5751 - sparse_categorical_accuracy: 0.4177 - val_loss: 1.4474 - val_sparse_categorical_accuracy: 0.4839\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 1.2854 - sparse_categorical_accuracy: 0.5290 - val_loss: 1.2784 - val_sparse_categorical_accuracy: 0.5472\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 6s 104ms/step - loss: 1.0886 - sparse_categorical_accuracy: 0.6066 - val_loss: 1.2068 - val_sparse_categorical_accuracy: 0.5756\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 6s 105ms/step - loss: 0.9033 - sparse_categorical_accuracy: 0.6817 - val_loss: 1.2073 - val_sparse_categorical_accuracy: 0.5887\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 0.7362 - sparse_categorical_accuracy: 0.7449 - val_loss: 1.2702 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 6s 104ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.7604 - val_loss: 1.3801 - val_sparse_categorical_accuracy: 0.5861\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - 6s 104ms/step - loss: 0.6644 - sparse_categorical_accuracy: 0.7601 - val_loss: 1.3547 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - 6s 103ms/step - loss: 0.5852 - sparse_categorical_accuracy: 0.7891 - val_loss: 1.5083 - val_sparse_categorical_accuracy: 0.5847\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - 6s 101ms/step - loss: 0.5428 - sparse_categorical_accuracy: 0.8052 - val_loss: 1.5647 - val_sparse_categorical_accuracy: 0.5790\n",
            "Epoch 11/20\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 0.4637 - sparse_categorical_accuracy: 0.8372 - val_loss: 1.5154 - val_sparse_categorical_accuracy: 0.5908\n",
            "Epoch 12/20\n",
            "62/62 [==============================] - 6s 103ms/step - loss: 0.3326 - sparse_categorical_accuracy: 0.8843 - val_loss: 1.5742 - val_sparse_categorical_accuracy: 0.6075\n",
            "Epoch 13/20\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 0.2190 - sparse_categorical_accuracy: 0.9258 - val_loss: 1.7474 - val_sparse_categorical_accuracy: 0.5897\n",
            "Epoch 14/20\n",
            "62/62 [==============================] - 6s 103ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9299 - val_loss: 1.7635 - val_sparse_categorical_accuracy: 0.6095\n",
            "Epoch 15/20\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9257 - val_loss: 1.8416 - val_sparse_categorical_accuracy: 0.5846\n",
            "Epoch 16/20\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.2264 - sparse_categorical_accuracy: 0.9242 - val_loss: 1.7621 - val_sparse_categorical_accuracy: 0.5845\n",
            "Epoch 17/20\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.1920 - sparse_categorical_accuracy: 0.9337 - val_loss: 1.9992 - val_sparse_categorical_accuracy: 0.5813\n",
            "Epoch 18/20\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.1641 - sparse_categorical_accuracy: 0.9440 - val_loss: 1.9622 - val_sparse_categorical_accuracy: 0.5865\n",
            "Epoch 19/20\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9742 - val_loss: 2.0230 - val_sparse_categorical_accuracy: 0.6089\n",
            "Epoch 20/20\n",
            "62/62 [==============================] - 6s 105ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9809 - val_loss: 2.1450 - val_sparse_categorical_accuracy: 0.6117\n"
          ]
        }
      ],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "ds_test = tf.data.Dataset.from_tensor_slices(  (ds_test_img ,ds_test_label) )\n",
        "ds_test = ds_test.batch(250)\n",
        "# train each constituent model with a seperate shard\n",
        "for i in range(4):\n",
        "    print('training model[', i, ']')\n",
        "    # convert data to tensors\n",
        "    data_set = tf.data.Dataset.from_tensor_slices(  (shards[i] ,labels_shards[i]) )\n",
        "    data_set = data_set.batch(250)\n",
        "    constituent_models[i].fit(\n",
        "        data_set,\n",
        "        epochs=20,\n",
        "        validation_data=ds_test,\n",
        "        verbose = 1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbqZ_S2Jcavm",
        "outputId": "71633081-685d-4365-e568-705dda10bcd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 1s 29ms/step - loss: 5.0291 - sparse_categorical_accuracy: 0.4334\n",
            "model 0  accuracy  0.43340003490448\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 4.3501 - sparse_categorical_accuracy: 0.5347\n",
            "model 1  accuracy  0.5347000360488892\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 2.9873 - sparse_categorical_accuracy: 0.4891\n",
            "model 2  accuracy  0.48910000920295715\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 2.1450 - sparse_categorical_accuracy: 0.6117\n",
            "model 3  accuracy  0.6117000579833984\n"
          ]
        }
      ],
      "source": [
        "#test the model accuracy without clustering the test data\n",
        "for i in range(4):\n",
        "  loss, acc = constituent_models[i].evaluate(ds_test)\n",
        "  print('model', i, \" accuracy \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcMBqiCLq8j7",
        "outputId": "b881578c-bd86-4938-8a42-15b7f25e7887"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p cluster_trained_models\n",
        "constituent_models[0].save('cluster_trained_models/constituent_model_0') \n",
        "constituent_models[1].save('cluster_trained_models/constituent_model_1')  \n",
        "constituent_models[2].save('cluster_trained_models/constituent_model_2') \n",
        "constituent_models[3].save('cluster_trained_models/constituent_model_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRLZmTYuWDg8",
        "outputId": "ce94f40d-ac2e-4ba8-cc2e-a18ee689c7ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cifar  cifar-10-python.tar.gz  cluster_trained_models  drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeApL7iFXzwp"
      },
      "outputs": [],
      "source": [
        "# predict the cluster of the testing data\n",
        "predict = predictor.predict(reshaped_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwxDv2smY_AH"
      },
      "outputs": [],
      "source": [
        "# predict testing data via its respective constituent model\n",
        "shards_test = [list() for x in range(4)]\n",
        "labels_shards_test = [list() for x in range(4)]\n",
        "\n",
        "for i in range(len(predict)):\n",
        "  if predict[i] == 0:\n",
        "    # put \"test_data[i]\" in shard_1\n",
        "    shards_test[0].append(test_data[i])\n",
        "    labels_shards_test[0].append(test_labels[i])\n",
        "  elif predict[i] == 1:\n",
        "    # put \"test_data[i]\" in shard_2\n",
        "    shards_test[1].append(test_data[i])\n",
        "    labels_shards_test[1].append(test_labels[i])\n",
        "  elif predict[i] == 2:\n",
        "    # put \"test_data[i]\" in shard_3\n",
        "    shards_test[2].append(test_data[i])\n",
        "    labels_shards_test[2].append(test_labels[i])\n",
        "  else:\n",
        "    # put \"test_data[i]\" in shard_4\n",
        "    shards_test[3].append(test_data[i])\n",
        "    labels_shards_test[3].append(test_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7DWstr4ZJSt",
        "outputId": "bd1fb274-0485-4c16-a004-97213b07547c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 2s 167ms/step - loss: 2.3146 - sparse_categorical_accuracy: 0.1265\n",
            "model 0  accuracy  0.12645012140274048\n",
            "21/21 [==============================] - 4s 195ms/step - loss: 1.8333 - sparse_categorical_accuracy: 0.3515\n",
            "model 1  accuracy  0.35145196318626404\n",
            "24/24 [==============================] - 4s 167ms/step - loss: 1.6820 - sparse_categorical_accuracy: 0.3876\n",
            "model 2  accuracy  0.38756614923477173\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.8640 - sparse_categorical_accuracy: 0.7065\n",
            "model 3  accuracy  0.7065471410751343\n"
          ]
        }
      ],
      "source": [
        "# evaluate the accuracy of each constituent model\n",
        "for i in range(4):\n",
        "  ds_test = tf.data.Dataset.from_tensor_slices(  (shards_test[i] ,labels_shards_test[i]) )\n",
        "  ds_test = ds_test.batch(128)\n",
        "  loss, acc = constituent_models[i].evaluate(ds_test)\n",
        "  print('model', i, \" accuracy \", acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
